# QIS数据系统开发记录——02

此时项目的文件结构如下（省略部分文件，如__init__.py）：

```
QUANTITATIVE_INVESTMENT
├── doc
├── conf
├── logs
├── FinanceDataAPI  （数据系统子项目）
|   ├── python      （数据系统python源代码根目录）
|   |   ├── logger  （日志模块）
|   |   ├── market_data （市场数据模块）
|   |   |   ├── trade_day   （交易日数据模块）
|   |   ├── utils   （工具模块）
|   |   ├── server_main.py  （数据系统程序入口点）
|   |   ├── settings.py   （数据系统常量配置）
|   ├── README.md
├── README.md
```

这里我们先不着急写市场数据部分的代码，还是看回一开始的交易日数据，我们这里要做架构优化，尽可能的实现代码重用和去耦合。

---
## 架构优化——组件抽象

在数据部分，对于具体的某类数据的生产过程（例如交易日数据，往后还会有市场数据等），我们的模型一般都是数据生产（producer），数据处理（processor）和数据存储（storager）。

我们知道，这里的三个部分是我们规定好承接起来的，就像一条流水线上的三个工序，或者三个组件一样。

既然是三个“组件”，也就是说这三个部分是具有同一性的，我们可以编写一个`ComponentBase`
基类来对组件进行抽象。因为这里单单是数据部分的一种场景，我们现阶段只设计了三个部分，为了拓展性来讲，以后可能还有其他的部分，像数据路由部分，数据缓存部分等等，这些也可以看作是组件。（为什么要设计`ComponentBase`
的原因）

新建_base（pipeline/_base）文件夹并添加一个基类文件`component_base.py`，代码如下：

```python
# component_base.py
class ComponentBase(object):
    _component_name = None

    def __init__(self, *args, **kwargs):
        self._input_data = None
        self._output_data = None
        pass

    @classmethod
    def get_component_name(cls) -> str:
        return cls._component_name

    @classmethod
    def set_component_name(cls, name: str):
        cls._component_name = name

    @property
    def input_data(self):
        return self._input_data

    @input_data.setter
    def input_data(self, data):
        self._input_data = data

    @property
    def output_data(self):
        return self._output_data

    @output_data.setter
    def output_data(self, data):
        self._output_data = data

    def run(self, *args, **kwargs):
        raise NotImplementedError

```

可以看到我们将所有组件的种类抽象出来了几个共同特性：

- `component_name`：组件名称
- `input_data`：输入数据
- `output_data`：输出数据
- `run`：运行组件

---

接下来我们回到我们现阶段的数据场景，就三个部分（producer，processor，storager）。 这三个部分可以抽象成三个基类，不同种类的数据可以通过继承这些类并实现具体功能。

这里添加三个基类文件在_base（pipeline/_base）文件夹中

- producer_base.py
- processor_base.py
- storager_base.py

这三个基类的代码如下：

```python
# producer_base.py
from . import ComponentBase
import pandas as pd


class ProducerBase(ComponentBase):
    def __init__(self, *args, **kwargs):
        super(ProducerBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.produce(*args, **kwargs)

    def produce(self, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

```python
# processor_base.py
from . import ComponentBase
import pandas as pd


class ProcessorBase(ComponentBase):
    def __init__(self, *args, **kwargs):
        super(ProcessorBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.process(self.input_data, *args, **kwargs)

    def process(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

```python
# storager_base.py
from . import ComponentBase
import pandas as pd


class StoragerBase(ComponentBase):

    def __init__(self, *args, **kwargs):
        super(StoragerBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.storage(self.input_data, *args, **kwargs)

    def storage(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

为了让pipeline形成一个包以及方便import，我们在_base（pipeline/_base）文件夹中添加一个`__init__.py`文件，内容如下：

```python
from .component_base import ComponentBase
from .producer_base import ProducerBase
from .processor_base import ProcessorBase
from .storager_base import StoragerBase

```

---

现在我们以交易日数据为例，将具体的过程实现

新建一个交易日数据的python包（market_data/trade_day/bao_stock），目录结构如下：

```
trade_day/bao_stock
├── __init__.py
├── producer.py
├── processor.py
└── storager.py
```

producer.py代码如下：

```python
import baostock as bs
import pandas as pd
import numpy as np
from pipeline import ProducerBase


class TradeDayProducer(ProducerBase):
    def __init__(self, *args, **kwargs):
        super(TradeDayProducer, self).__init__(*args, **kwargs)

    def produce(self, *args, **kwargs) -> pd.DataFrame:
        return self.get_trade_day_data()

    ...

    def get_trade_day_data(self) -> pd.DataFrame:
        lg = bs.login()
        today = np.datetime64('today') - 1
        DAY_NUM_PER_YEAR = 365
        pre_day_num = DAY_NUM_PER_YEAR * 2
        start_date = today - np.timedelta64(pre_day_num, 'D')
        end_date = np.datetime64('today', 'Y') + np.timedelta64(1, 'Y') - np.timedelta64(1, 'D')
        rs = bs.query_trade_dates(start_date=start_date, end_date=end_date)
        data_list = []
        while (rs.error_code == '0') & rs.next():
            data_list.append(rs.get_row_data())
        result = pd.DataFrame(data_list, columns=rs.fields)
        bs.logout()
        return result
```

processor.py代码如下：

```python
import pandas as pd
from pipeline import ProcessorBase


class TradeDayProcessor(ProcessorBase):
    def __init__(self, *args, **kwargs):
        super(TradeDayProcessor, self).__init__(*args, **kwargs)

    def process(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        return self.process_trade_day_data(input_data)

    def process_trade_day_data(self, trade_day_data: pd.DataFrame) -> pd.DataFrame:
        in_table = trade_day_data.copy()

        out_table_column_name_list = ["date", "is_trade_day"]

        in_table_date_column_name = "calendar_date"
        in_table_is_trade_day_column_name = "is_trading_day"

        in_table_date_column = in_table[in_table_date_column_name]
        in_table_is_trade_day_column = in_table[in_table_is_trade_day_column_name]

        try:
            in_table_date_column = pd.to_datetime(in_table_date_column)
            in_table_is_trade_day_column = in_table_is_trade_day_column.astype("uint8")
        except Exception as e:
            print(f"Error: {e}")

        out_table = pd.DataFrame({out_table_column_name_list[0]: in_table_date_column,
                                  out_table_column_name_list[1]: in_table_is_trade_day_column})

        return out_table

```

storager.py代码如下：

```python
import pandas as pd
import pymysql
import pymysql.cursors
from pipeline import StoragerBase

host = '127.0.0.1'
port = 3307
user = 'root'
password = '123456'
database = 'market_data'
charset = 'utf8mb4'
cursorclass = pymysql.cursors.DictCursor


class TradeDayStorager(StoragerBase):
    def __init__(self, *args, **kwargs):
        super(TradeDayStorager, self).__init__(*args, **kwargs)

    def storage(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        return self.storage_trade_day_data(input_data)

    def storage_trade_day_data(self, processed_trade_day_data: pd.DataFrame) -> pd.DataFrame:
        conn = pymysql.connect(host=host, port=port, user=user, password=password, database=database, charset=charset,
                               cursorclass=cursorclass)
        # 遍历DataFrame的每一行
        with conn:
            with conn.cursor() as cursor:
                for index, row in processed_trade_day_data.iterrows():
                    # print(*row)
                    sql = "CALL insert_trade_day(%s, %s)"
                    cursor.execute(sql, (*row,))
            conn.commit()

        success = pd.DataFrame([['success']], columns=['status'])
        return success

```

> 为什么我们不让`TradeDayProducer`直接继承`ComponentBase`，而是要再抽象一个`ProcessorBase`呢？
>
> 因为逻辑上来讲`TradeDayProducer`是实体，是具体的一个交易日**数据生产组件**，还会有交易**数据生产组件**，价格**数据生产组件
**等，这里的`ProcessorBase`正是对**数据生产组件**的抽象，代表一类数据生产组件。
>
> 而除了生产**组件**，还会有处理**组件**，存储**组件**，前面说过不同种类组件之间也有相同的地方，所以这里需要`ComponentBase`对
**组件种类**进行抽象，同时又可以是实体组件的抽象（父类的父类），这样就形成了一个完整的抽象体系。


>
其实以上就是架构设计中关于解耦的思想，本质上都是为了复用和高拓展性。但是比如说我们以后的项目确定不会有别的种类的组件，只有现在的三个部分（producer，processor，storager），那么不这么抽象也问题不大，技术服务于需求。只是作为一个项目开发者，前人栽树后人乘凉，在项目前期花一些时间去思考和设计架构，对后期的维护和拓展都是有好处的。这样自己以后看代码也舒服，后来的其他项目开发者和维护者也能很方便地融入进来，项目也能得以高效的发展，产品也会愈发健硕。

---

## 架构优化——流水线

我们这里再添加一个流水线类`Pipeline`，这个类的作用是将三个基类组合起来，形成一个完整的数据处理流程。

新建文件pipeline.py（pipeline/_pipeline.py）：

```python
import queue
from typing import Type
from pipeline import ComponentBase


class Pipeline(object):
    def __init__(self, *args, **kwargs):
        self.component_name_to_class_dict = {}
        self.is_running = False
        self.input_data = None

        self._task_queue: queue.Queue[tuple[Type[ComponentBase], dict]] = queue.Queue()
        self._output_data = None

    def add_component(self, component_class: Type[ComponentBase], component_arguments: dict):
        self._task_queue.put((component_class, component_arguments))
        self.component_name_to_class_dict[component_class.get_component_name()] = component_class

    def run(self):  # todo: 暂时使用pipeline作为运行对象，后续考虑使用其他线程模型
        self.is_running = True
        pre_component_output = self.input_data
        while not self._task_queue.empty():
            component_class, component_arguments = self._task_queue.get()
            component_object = component_class()
            component_object.input_data = pre_component_output
            component_object.run(**component_arguments)
            pre_component_output = component_object.output_data
        self.is_running = False
        self._output_data = pre_component_output

    @property
    def output_data(self):
        return self._output_data

```

为了方便pipeline包的import，在`__init__py`中添加内容如下：

```python
from ._base import ComponentBase, ProducerBase, ProcessorBase, StoragerBase
from ._pipeline import Pipeline

```
---

我们打算在导入模块的时候使用反射，这样我们设定一个放置组件的目录（定为`pipeline/components`
）,将要导入的组件都写在这个目录下，然后我们在导入模块的时候，遍历这个目录下的所有py文件，使用反射进行动态导入。

以前面写好的交易日数据模块为例，我们在`pipeline/components`目录下创建一个`trade_day.py`文件，内容如下：

```python
from market_data.trade_day.bao_stock.producer import TradeDayProducer as BaoStockTradeDayProducer
from market_data.trade_day.bao_stock.processor import TradeDayProcessor as BaoStockTradeDayProcessor
from market_data.trade_day.bao_stock.storager import TradeDayStorager as BaoStockTradeDayStorager

BaoStockTradeDayProducer.set_component_name('BaoStockTradeDayProducer')
BaoStockTradeDayProcessor.set_component_name('BaoStockTradeDayProcessor')
BaoStockTradeDayStorager.set_component_name('BaoStockTradeDayStorager')
```

---

## 架构优化——组件管理器

我们创建一个`manager`包，用于管理组件，这里我们先创建一个`component_manager.py`文件，代码如下：

```python
from pipeline import ComponentBase
from pathlib import Path
import inspect
import os
import importlib
from utils.path_utils import get_module_name_by_path
from utils.log_utils import get_logger

logger = get_logger()

PIPELINE_MODULE_PATH = os.path.dirname(importlib.import_module('pipeline').__file__)
MODULE_ROOT_PATH = Path(PIPELINE_MODULE_PATH).parent


class ComponentManager:
    __instance = None

    def __new__(cls, *args, **kwargs):
        if cls.__instance is None:
            cls.__instance = super(ComponentManager, cls).__new__(cls)
        return cls.__instance

    def __init__(self, *args, **kwargs):
        self._component_name_to_class_dict = {}

        ...

    @classmethod
    def get_instance(cls):
        if cls.__instance is None:
            cls.__instance = cls()
        return cls.__instance

    def get_component_class_by_name(self, component_name):
        return self._component_name_to_class_dict.get(component_name)

    def register_component(self):
        components_path = os.path.join(PIPELINE_MODULE_PATH, 'components')
        self.__register_component_from_dir(components_path)

    def __register_component_from_dir(self, components_path):
        pipeline_module_path_list = []
        component_class_list = []
        self._component_name_to_class_dict = {}

        # 导入components目录下的所有py文件
        for root, dirs, files in os.walk(components_path):
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    pipeline_module_path_list.append(file_path)

        for pipeline_module_path in pipeline_module_path_list:
            logger.info(f"Registering components from {pipeline_module_path}")
            module_name = get_module_name_by_path(Path(pipeline_module_path), Path(MODULE_ROOT_PATH))
            module = importlib.import_module(module_name)
            for name, obj in inspect.getmembers(module):
                if inspect.isclass(obj) and issubclass(obj, ComponentBase) and obj != ComponentBase:
                    component_class_list.append(obj)
                    self._component_name_to_class_dict[obj.get_component_name()] = obj

        logger.info(f"component_name_to_class_dict: {self._component_name_to_class_dict}")

```


最后在server_main.py中尝试运行

```python
if __name__ == '__main__':
    from pipeline import  Pipeline
    from manager.component_manager import ComponentManager

    component_manager = ComponentManager.get_instance()
    component_manager.register_component()  # 注册组件

    pipeline = Pipeline()
    pipeline.add_component(component_manager.get_component_class_by_name('BaoStockTradeDayProducer'),{})
    pipeline.add_component(component_manager.get_component_class_by_name('BaoStockTradeDayProcessor'),{})
    pipeline.add_component(component_manager.get_component_class_by_name('BaoStockTradeDayStorager'),{})

    print(pipeline.component_name_to_class_dict)
    pipeline.run()
    print(pipeline.output_data)

```

代码非常优美！

此处使用反射也是为了将主代码和实现逻辑的代码解耦分离，后续会尝试实现一个调度服务器（主代码），支持随时导入代码并运行任务（pipeline），这样就可以将程序运行和开发过程分离，无需每次写完代码都要重新启动程序。

TODO: 

## ..