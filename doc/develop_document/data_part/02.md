# 数据部分开发记录——02

这里我们先不着急写市场数据部分的代码，还是看回一开始的交易日数据，我们这里要做架构优化，尽可能的实现代码重用和去耦合。

---

在数据部分，对于具体的某类数据的生产过程（例如交易日数据，往后还会有市场数据等），我们的模型一般都是数据获取（producer），数据处理（processor）和数据存储（storager）。

我们知道，这里的三个部分是我们规定好承接起来的，就像一条流水线上的三个工序，或者三个组件一样。

既然是三个“组件”，也就是说这三个部分是具有同一性的，我们可以编写一个`ComponentBase`
基类来对组件进行抽象。因为这里单单是数据部分的一种场景，我们现阶段只设计了三个部分，为了拓展性来讲，以后可能还有其他的部分，像数据路由部分，数据缓存部分等等，这些也可以看作是组件。（为什么要设计`ComponentBase`
的原因）

新建_base（market_data/pipeline/_base）文件夹并添加一个基类文件`component_base.py`，代码如下：

```python
# component_base.py
class ComponentBase(object):

    def __init__(self, *args, **kwargs):
        self._component_name = None
        self._input_data = None
        self._output_data = None

        pass

    def get_component_name(cls):
        return self._component_name

    def set_component_name(self, name):
        self._component_name = name

    @property
    def input_data(self):
        return self._input_data

    @input_data.setter
    def input_data(self, data):
        self._input_data = data

    @property
    def output_data(self):
        return self._output_data

    @output_data.setter
    def output_data(self, data):
        self._output_data = data

    def run(self, *args, **kwargs):
        raise NotImplementedError

```

可以看到我们将所有组件的种类抽象出来了几个共同特性：

- `component_name`：组件名称
- `input_data`：输入数据
- `output_data`：输出数据
- `run`：运行组件

---

接下来我们回到我们现阶段的数据场景，就三个部分（producer，processor，storager）。 这三个部分可以抽象成三个基类，不同种类的数据可以通过继承这些类并实现具体功能。

这里添加三个基类文件在_base（market_data/pipeline/_base）文件夹中

- producer_base.py
- processor_base.py
- storager_base.py

这三个基类的代码如下：

```python
# producer_base.py
from . import ComponentBase
import pandas as pd


class ProducerBase(ComponentBase):
    def __init__(self, *args, **kwargs):
        super(ProducerBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.produce(*args, **kwargs)

    def produce(self, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

```python
# processor_base.py
from . import ComponentBase
import pandas as pd


class ProcessorBase(ComponentBase):
    def __init__(self, *args, **kwargs):
        super(ProcessorBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.process(self.input_data, *args, **kwargs)

    def process(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

```python
# storager_base.py
from . import ComponentBase
import pandas as pd


class StoragerBase(ComponentBase):

    def __init__(self, *args, **kwargs):
        super(StoragerBase, self).__init__(*args, **kwargs)

    def run(self, *args, **kwargs):
        self.output_data = self.storage(self.input_data, *args, **kwargs)

    def storage(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        raise NotImplementedError

```

---

现在我们以交易日数据为例，将具体的过程实现

新建一个交易日数据的python包（market_data/pipeline/trade_day），目录结构如下：

```
trade_day
├── __init__.py
├── producer.py
├── processor.py
└── storager.py
```

producer.py代码如下：

```python
import baostock as bs
import pandas as pd
import numpy as np
from market_data.pipeline._base import ProducerBase


class TradeDayProducer(ProducerBase):

    def produce(self, *args, **kwargs) -> pd.DataFrame:
        return self.get_trade_day_data()

    ...

    def get_trade_day_data(self) -> pd.DataFrame:
        lg = bs.login()
        today = np.datetime64('today') - 1
        DAY_NUM_PER_YEAR = 365
        pre_day_num = DAY_NUM_PER_YEAR * 2
        start_date = today - np.timedelta64(pre_day_num, 'D')
        end_date = np.datetime64('today', 'Y') + np.timedelta64(1, 'Y') - np.timedelta64(1, 'D')
        rs = bs.query_trade_dates(start_date=start_date, end_date=end_date)
        data_list = []
        while (rs.error_code == '0') & rs.next():
            data_list.append(rs.get_row_data())
        result = pd.DataFrame(data_list, columns=rs.fields)
        bs.logout()
        return result
```

processor.py代码如下：

```python
import pandas as pd
from market_data.pipeline._base import processor_base


class TradeDayProcessor(processor_base.ProcessorBase):
    def __init__(self, *args, **kwargs):
        super(TradeDayProcessor, self).__init__(*args, **kwargs)

    def process(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        return self.process_trade_day_data(input_data)

    def process_trade_day_data(self, trade_day_data: pd.DataFrame) -> pd.DataFrame:
        in_table = trade_day_data.copy()

        out_table_column_name_list = ["date", "is_trade_day"]

        in_table_date_column_name = "calendar_date"
        in_table_is_trade_day_column_name = "is_trading_day"

        in_table_date_column = in_table[in_table_date_column_name]
        in_table_is_trade_day_column = in_table[in_table_is_trade_day_column_name]

        try:
            in_table_date_column = pd.to_datetime(in_table_date_column)
            in_table_is_trade_day_column = in_table_is_trade_day_column.astype("uint8")
        except Exception as e:
            print(f"Error: {e}")

        out_table = pd.DataFrame({out_table_column_name_list[0]: in_table_date_column,
                                  out_table_column_name_list[1]: in_table_is_trade_day_column})

        return out_table
```

storager.py代码如下：

```python
import pandas as pd
import pymysql
import pymysql.cursors
from market_data.pipeline._base import storager_base

host = '127.0.0.1'
port = 3307
user = 'root'
password = '123456'
database = 'market_data'
charset = 'utf8mb4'
cursorclass = pymysql.cursors.DictCursor


class TradeDayStorager(storager_base.StoragerBase):
    def __init__(self, *args, **kwargs):
        super(TradeDayStorager, self).__init__(*args, **kwargs)

    def storage(self, input_data: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:
        return self.storage_trade_day_data(input_data)

    def storage_trade_day_data(self, processed_trade_day_data: pd.DataFrame) -> pd.DataFrame:
        conn = pymysql.connect(host=host, port=port, user=user, password=password, database=database, charset=charset,
                               cursorclass=cursorclass)
        # 遍历DataFrame的每一行
        with conn:
            with conn.cursor() as cursor:
                for index, row in processed_trade_day_data.iterrows():
                    # print(*row)
                    sql = "CALL insert_trade_day(%s, %s)"
                    cursor.execute(sql, (*row,))
            conn.commit()

        success = pd.DataFrame([['success']], columns=['status'])
        return success

```

> 为什么我们不让`TradeDayProducer`直接继承`ComponentBase`，而是要再抽象一个`ProcessorBase`呢？
>
> 因为逻辑上来讲`TradeDayProducer`是实体，是具体的一个交易日**数据获取组件**，还会有交易**数据获取组件**，价格**数据获取组件
**等，这里的`ProcessorBase`正是对**数据获取组件**的抽象，代表一类数据获取组件。
>
> 而除了获取**组件**，还会有处理**组件**，存储**组件**，前面说过不同种类组件之间也有相同的地方，所以这里需要`ComponentBase`对
**组件种类**进行抽象，同时又可以是实体组件的抽象（父类的父类），这样就形成了一个完整的抽象体系。


>
其实以上就是架构设计中关于解耦的思想，本质上都是为了复用和高拓展性。但是比如说我们以后的项目确定不会有别的种类的组件，只有现在的三个部分（producer，processor，storager），那么不这么抽象也问题不大，技术服务于需求。只是作为一个项目开发者，前人栽树后人乘凉，在项目前期花一些时间去思考和设计架构，对后期的维护和拓展都是有好处的。这样自己以后看代码也舒服，后来的其他项目开发者和维护者也能很方便地融入进来，项目也能得以高效的发展，产品也会愈发健硕。

---


我们这里再添加一个流水线类`Pipeline`，这个类的作用是将三个基类组合起来，形成一个完整的数据处理流程。

新建文件pipeline.py（market_data/pipeline/pipeline.py）：

```python
import queue


class Pipeline(object):
    def __init__(self, *args, **kwargs):
        self.component_class_queue = queue.Queue()
        self.component_name_to_class_dict = {}
        self.is_running = False
        self.input_data = None
        self._output_data = None

    def add_component_class(self, component_class):
        self.component_class_queue.put(component_class)
        self.component_name_to_class_dict[component_class.__name__] = component_class

    def run(self):
        self.is_running = True
        pre_component_output = self.input_data
        while not self.component_class_queue.empty():
            component_class = self.component_class_queue.get()
            component_object = component_class()
            component_object.input_data = pre_component_output
            component_object.run()
            pre_component_output = component_object.output_data
        self.is_running = False
        self._output_data = pre_component_output

    @property
    def output_data(self):
        return self._output_data
```

---

最后运行的示例代码

```python
if __name__ == '__main__':
    from market_data.pipeline._base import *
    from market_data.pipeline.pipeline import Pipeline
    import inspect
    import os

    import importlib
    import sys

    PIPELINE_MODULE_PATH = os.path.dirname(importlib.import_module('market_data.pipeline').__file__)
    components_path = os.path.join(PIPELINE_MODULE_PATH, 'components')

    pipeline_module_path_list = []
    component_class_list = []
    component_name_to_class_dict = {}

    # 遍历components目录下的所有py文件
    for root, dirs, files in os.walk(components_path):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                pipeline_module_path_list.append(file_path)

    from pathlib import Path


    def _get_module_name_by_path(path, base):
        return '.'.join(path.resolve().relative_to(base.resolve()).with_suffix('').parts)


    for pipeline_module_path in pipeline_module_path_list:
        module_name = _get_module_name_by_path(Path(pipeline_module_path), Path(PIPELINE_MODULE_PATH))
        module = importlib.import_module(module_name)
        for name, obj in inspect.getmembers(module):
            if inspect.isclass(obj) and issubclass(obj, ComponentBase):
                component_class_list.append(obj)
                component_name_to_class_dict[obj.__name__] = obj

    print(component_name_to_class_dict)

    pipeline = Pipeline()
    pipeline.add_component_class(component_name_to_class_dict['TradeDayProducer'])
    pipeline.add_component_class(component_name_to_class_dict['TradeDayProcessor'])
    pipeline.add_component_class(component_name_to_class_dict['TradeDayStorager'])

    print(pipeline.component_name_to_class_dict)

    pipeline.run()

    print(pipeline.output_data)

```

此处使用反射也是为了将主代码和实现逻辑的代码解耦分离，后续会尝试实现一个调度服务器（主代码），支持随时导入代码并运行任务（pipeline），这样就可以将程序运行和开发过程分离，无需每次写完代码都要重新启动程序。

TODO: 

